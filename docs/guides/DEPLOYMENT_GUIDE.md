# Deployment Guide - HS2 Assurance Intelligence

**Version**: 1.0
**Last Updated**: November 25, 2024
**Target**: Local Development, Staging, Production

---

## ğŸ“‹ Overview

This guide covers deployment of the HS2 Assurance Intelligence Demonstrator across three environments:

1. **Local Development** - Docker Compose on developer laptop
2. **Staging** - Cloud-based staging environment (AWS/Azure)
3. **Production** - Enterprise-grade deployment with HA, monitoring

---

## ğŸš€ Local Development Deployment

### Prerequisites

- **Docker Desktop** 4.0+ (includes docker-compose)
- **8GB RAM** minimum (16GB recommended)
- **20GB free disk space**
- **Git** for repository access

### Quick Start (Recommended)

```bash
# 1. Clone repository
git clone <repository-url>
cd ground-truth

# 2. Launch complete environment
./scripts/demo.sh

# 3. Verify deployment
curl http://localhost:8002/health
open http://localhost:8002/docs
```

**Done! The system is ready in ~60 seconds.**

### Manual Step-by-Step

If you prefer manual control or encounter issues:

#### Step 1: Start Docker Services

```bash
# Start all services
docker compose up -d

# Verify services are running
docker compose ps

# Expected output:
# NAME                          STATUS
# infrastructure-postgres       Up
# infrastructure-backend        Up
# infrastructure-frontend       Up
# infrastructure-redis          Up
# infrastructure-minio          Up
```

#### Step 2: Create Database Tables

```bash
# Create HS2 tables
docker compose exec backend python scripts/database/create_hs2_tables.py

# Verify tables created
docker compose exec postgres psql -U gpr_user -d gpr_db -c "\dt hs2_*"
```

#### Step 3: Generate & Seed Data

```bash
# Generate placeholder data
docker compose exec backend python scripts/generate_placeholder_data.py

# Seed database
docker compose exec backend python scripts/seed_database.py

# Verify data loaded
docker compose exec postgres psql -U gpr_user -d gpr_db -c "
  SELECT 'Assets', COUNT(*) FROM hs2_assets
  UNION ALL SELECT 'Deliverables', COUNT(*) FROM hs2_deliverables;
"
```

#### Step 4: Run TAEM Evaluation

```bash
# Evaluate all assets
docker compose exec backend python scripts/evaluate_all_assets.py

# Verify evaluations stored
docker compose exec postgres psql -U gpr_user -d gpr_db -c "
  SELECT COUNT(*) FROM hs2_rule_evaluations;
"
# Expected: 300 (50 assets Ã— 6 rules)
```

### Access URLs

| Service | URL | Description |
|---------|-----|-------------|
| **Backend API** | http://localhost:8002 | FastAPI REST API |
| **API Docs** | http://localhost:8002/docs | Swagger UI |
| **API Redoc** | http://localhost:8002/redoc | Alternative docs |
| **Frontend** | http://localhost:3003 | React UI (if implemented) |
| **MinIO Console** | http://localhost:9011 | S3-compatible storage |
| **PostgreSQL** | localhost:5433 | Database (external access) |
| **Redis** | localhost:6380| Cache (external access) |

### Environment Variables

Default values are in `.env` (auto-generated by `setup_env.sh`):

```bash
# Database
POSTGRES_USER=gpr_user
POSTGRES_PASSWORD=<generated>
POSTGRES_DB=gpr_db
DATABASE_URL=postgresql://gpr_user:<password>@postgres:5432/gpr_db

# MinIO (S3-compatible storage)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin

# Backend
SECRET_KEY=<generated>
CORS_ORIGINS=http://localhost:3003,http://localhost:8002

# Optional (Phase 2)
OPENAI_API_KEY=<your-key-here>
PINECONE_API_KEY=<your-key-here>
```

To customize, edit `.env` and restart services:
```bash
nano .env
docker compose restart
```

### Stopping & Cleanup

```bash
# Stop all services
docker compose down

# Stop and remove volumes (CAUTION: deletes all data)
docker compose down -v

# Remove all images (full cleanup)
docker compose down --rmi all -v
```

---

## â˜ï¸ Staging Deployment (AWS)

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AWS VPC (10.0.0.0/16)                              â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Public Subnet (10.0.1.0/24)                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚  ALB         â”‚  â”‚  NAT Gateway â”‚         â”‚  â”‚
â”‚  â”‚  â”‚  (Port 443)  â”‚  â”‚              â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚            â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Private Subnet (10.0.2.0/24)                â”‚  â”‚
â”‚  â”‚         â†“                                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚  ECS Fargate â”‚  â”‚  ECS Fargate â”‚         â”‚  â”‚
â”‚  â”‚  â”‚  (Backend)   â”‚  â”‚  (Frontend)  â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚            â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Data Subnet (10.0.3.0/24)                   â”‚  â”‚
â”‚  â”‚         â†“                                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚  RDS Postgresâ”‚  â”‚  ElastiCache â”‚         â”‚  â”‚
â”‚  â”‚  â”‚  Multi-AZ    â”‚  â”‚  Redis       â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Prerequisites

- AWS Account with appropriate permissions
- AWS CLI installed and configured
- Terraform 1.0+ (or CloudFormation)
- Docker images pushed to ECR

### Step 1: Build & Push Docker Images

```bash
# Login to ECR
aws ecr get-login-password --region us-east-1 | \
  docker login --username AWS --password-stdin <account-id>.dkr.ecr.us-east-1.amazonaws.com

# Build backend image
cd backend
docker build -t hs2-backend:latest .
docker tag hs2-backend:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/hs2-backend:latest
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/hs2-backend:latest

# Build frontend image (when ready)
cd ../frontend
docker build -t hs2-frontend:latest .
docker tag hs2-frontend:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/hs2-frontend:latest
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/hs2-frontend:latest
```

### Step 2: Provision Infrastructure (Terraform)

```hcl
# terraform/main.tf
terraform {
  required_version = ">= 1.0"

  backend "s3" {
    bucket = "hs2-terraform-state"
    key    = "staging/terraform.tfstate"
    region = "us-east-1"
  }
}

provider "aws" {
  region = "us-east-1"
}

# VPC
module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "~> 3.0"

  name = "hs2-staging-vpc"
  cidr = "10.0.0.0/16"

  azs              = ["us-east-1a", "us-east-1b"]
  private_subnets  = ["10.0.2.0/24", "10.0.3.0/24"]
  public_subnets   = ["10.0.1.0/24", "10.0.4.0/24"]
  database_subnets = ["10.0.5.0/24", "10.0.6.0/24"]

  enable_nat_gateway = true
  single_nat_gateway = false  # Use 2 NAT gateways for HA
}

# RDS PostgreSQL
module "rds" {
  source  = "terraform-aws-modules/rds/aws"
  version = "~> 5.0"

  identifier = "hs2-staging-db"

  engine            = "postgres"
  engine_version    = "16.0"
  instance_class    = "db.t3.large"
  allocated_storage = 100

  db_name  = "hs2_db"
  username = "hs2_admin"
  password = random_password.db_password.result

  multi_az               = true
  db_subnet_group_name   = module.vpc.database_subnet_group
  vpc_security_group_ids = [aws_security_group.rds.id]

  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "mon:04:00-mon:05:00"

  enabled_cloudwatch_logs_exports = ["postgresql", "upgrade"]
}

# ElastiCache Redis
resource "aws_elasticache_cluster" "redis" {
  cluster_id           = "hs2-staging-redis"
  engine               = "redis"
  node_type            = "cache.t3.medium"
  num_cache_nodes      = 1
  parameter_group_name = "default.redis7"
  port                 = 6379
  subnet_group_name    = aws_elasticache_subnet_group.redis.name
  security_group_ids   = [aws_security_group.redis.id]
}

# ECS Cluster
resource "aws_ecs_cluster" "main" {
  name = "hs2-staging"

  setting {
    name  = "containerInsights"
    value = "enabled"
  }
}

# ECS Task Definition (Backend)
resource "aws_ecs_task_definition" "backend" {
  family                   = "hs2-backend"
  requires_compatibilities = ["FARGATE"]
  network_mode            = "awsvpc"
  cpu                     = "1024"
  memory                  = "2048"

  container_definitions = jsonencode([
    {
      name      = "backend"
      image     = "${var.ecr_repository}/hs2-backend:latest"
      cpu       = 1024
      memory    = 2048
      essential = true

      portMappings = [
        {
          containerPort = 8000
          hostPort      = 8000
          protocol      = "tcp"
        }
      ]

      environment = [
        {
          name  = "DATABASE_URL"
          value = "postgresql://${module.rds.db_instance_username}:${random_password.db_password.result}@${module.rds.db_instance_endpoint}/${module.rds.db_instance_name}"
        },
        {
          name  = "REDIS_URL"
          value = "redis://${aws_elasticache_cluster.redis.cache_nodes[0].address}:6379"
        }
      ]

      logConfiguration = {
        logDriver = "awslogs"
        options = {
          awslogs-group         = "/ecs/hs2-backend"
          awslogs-region        = "us-east-1"
          awslogs-stream-prefix = "ecs"
        }
      }
    }
  ])
}

# ECS Service (Backend)
resource "aws_ecs_service" "backend" {
  name            = "hs2-backend"
  cluster         = aws_ecs_cluster.main.id
  task_definition = aws_ecs_task_definition.backend.arn
  desired_count   = 2
  launch_type     = "FARGATE"

  network_configuration {
    subnets          = module.vpc.private_subnets
    security_groups  = [aws_security_group.backend.id]
    assign_public_ip = false
  }

  load_balancer {
    target_group_arn = aws_lb_target_group.backend.arn
    container_name   = "backend"
    container_port   = 8000
  }

  depends_on = [aws_lb_listener.https]
}

# Application Load Balancer
resource "aws_lb" "main" {
  name               = "hs2-staging-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = module.vpc.public_subnets
}

resource "aws_lb_target_group" "backend" {
  name     = "hs2-backend-tg"
  port     = 8000
  protocol = "HTTP"
  vpc_id   = module.vpc.vpc_id
  target_type = "ip"

  health_check {
    enabled             = true
    path                = "/health"
    interval            = 30
    timeout             = 5
    healthy_threshold   = 2
    unhealthy_threshold = 2
  }
}

resource "aws_lb_listener" "https" {
  load_balancer_arn = aws_lb.main.arn
  port              = "443"
  protocol          = "HTTPS"
  ssl_policy        = "ELBSecurityPolicy-TLS-1-2-2017-01"
  certificate_arn   = aws_acm_certificate.main.arn

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.backend.arn
  }
}

# ACM Certificate (for HTTPS)
resource "aws_acm_certificate" "main" {
  domain_name       = "hs2-staging.yourdomain.com"
  validation_method = "DNS"

  lifecycle {
    create_before_destroy = true
  }
}
```

### Step 3: Deploy with Terraform

```bash
cd terraform

# Initialize Terraform
terraform init

# Plan deployment
terraform plan -out=tfplan

# Apply deployment
terraform apply tfplan

# Get outputs (ALB URL, RDS endpoint, etc.)
terraform output
```

### Step 4: Initialize Database

```bash
# Connect to ECS task
aws ecs execute-command \
  --cluster hs2-staging \
  --task <task-id> \
  --container backend \
  --interactive \
  --command "/bin/bash"

# Inside container
python scripts/database/create_hs2_tables.py
python scripts/seed_taem_rules.py

# If using real HS2 data, run ETL pipeline
python scripts/etl/sync_from_aims.py
```

### Step 5: Configure DNS

```bash
# Get ALB DNS name
aws elbv2 describe-load-balancers \
  --names hs2-staging-alb \
  --query 'LoadBalancers[0].DNSName' \
  --output text

# Create CNAME record
# hs2-staging.yourdomain.com -> hs2-staging-alb-123456789.us-east-1.elb.amazonaws.com
```

### Step 6: Verify Deployment

```bash
# Check health endpoint
curl https://hs2-staging.yourdomain.com/health

# Check API docs
open https://hs2-staging.yourdomain.com/docs

# Run smoke tests
pytest tests/integration/test_api_smoke.py --base-url=https://hs2-staging.yourdomain.com
```

---

## ğŸ¢ Production Deployment

### Additional Requirements for Production

1. **High Availability**
   - Multi-AZ deployment (at least 2 availability zones)
   - Auto-scaling (ECS or Kubernetes)
   - RDS Multi-AZ with read replicas
   - Redis cluster mode

2. **Security**
   - AWS WAF on ALB
   - AWS Secrets Manager for credentials
   - VPC endpoints for AWS services
   - Network ACLs and Security Groups
   - IAM roles with least privilege

3. **Monitoring & Alerting**
   - CloudWatch Logs and Metrics
   - Application Performance Monitoring (Datadog, New Relic)
   - PagerDuty/Opsgenie for on-call
   - Distributed tracing (AWS X-Ray)

4. **Backup & Disaster Recovery**
   - RDS automated backups (daily)
   - Point-in-time recovery (PITR)
   - Cross-region replication
   - Regular disaster recovery drills

5. **CI/CD Pipeline**
   - GitHub Actions or Jenkins
   - Automated testing (unit, integration, E2E)
   - Blue-green deployments
   - Rollback capability

### Production Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Multi-Region Active-Passive Setup                           â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Primary Region         â”‚  â”‚  DR Region              â”‚   â”‚
â”‚  â”‚  (us-east-1)            â”‚  â”‚  (eu-west-1)            â”‚   â”‚
â”‚  â”‚                         â”‚  â”‚                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚  Route 53    â”‚â—„â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”¤  Health Checkâ”‚      â”‚   â”‚
â”‚  â”‚  â”‚  (Active)    â”‚       â”‚  â”‚  â”‚              â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚         â”‚               â”‚  â”‚                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚  CloudFront   â”‚      â”‚  â”‚  â”‚  CloudFront  â”‚      â”‚   â”‚
â”‚  â”‚  â”‚  (CDN)        â”‚      â”‚  â”‚  â”‚  (Standby)   â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚         â”‚               â”‚  â”‚                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚  WAF          â”‚      â”‚  â”‚  â”‚  WAF         â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚         â”‚               â”‚  â”‚                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚  ALB          â”‚      â”‚  â”‚  â”‚  ALB         â”‚      â”‚   â”‚
â”‚  â”‚  â”‚  Multi-AZ     â”‚      â”‚  â”‚  â”‚  Multi-AZ    â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚         â”‚               â”‚  â”‚                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚  ECS Fargate  â”‚      â”‚  â”‚  â”‚  ECS Fargate â”‚      â”‚   â”‚
â”‚  â”‚  â”‚  (4+ tasks)   â”‚      â”‚  â”‚  â”‚  (Standby)   â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚         â”‚               â”‚  â”‚                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚  RDS Primary  â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â–ºâ”‚  RDS Replica â”‚      â”‚   â”‚
â”‚  â”‚  â”‚  Multi-AZ     â”‚      â”‚  â”‚  â”‚  (Read-only) â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Production Checklist

- [ ] Multi-AZ deployment in 2+ availability zones
- [ ] Auto-scaling enabled (target: 2-10 tasks)
- [ ] RDS Multi-AZ with read replica in DR region
- [ ] Redis cluster mode with automatic failover
- [ ] CloudFront CDN for static assets
- [ ] AWS WAF rules configured (SQL injection, XSS protection)
- [ ] Secrets Manager for all credentials
- [ ] CloudWatch Logs with 7-year retention (CDM compliance)
- [ ] CloudWatch alarms (CPU, memory, error rate, latency)
- [ ] SNS topics for critical alerts
- [ ] PagerDuty integration for on-call
- [ ] Automated backups (daily RDS snapshots)
- [ ] Cross-region replication configured
- [ ] Blue-green deployment pipeline
- [ ] Automated rollback on health check failure
- [ ] Load testing completed (1000+ concurrent users)
- [ ] Security audit completed (penetration testing)
- [ ] GDPR compliance validation
- [ ] CDM 2015 compliance validation
- [ ] Disaster recovery drill completed
- [ ] Runbook documented for operations team

---

## ğŸ”„ CI/CD Pipeline

### GitHub Actions Example

```yaml
# .github/workflows/deploy.yml
name: Deploy HS2 Platform

on:
  push:
    branches:
      - main
      - staging

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r backend/requirements.txt

      - name: Run unit tests
        run: |
          pytest backend/tests/ --cov=backend/app --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build and push backend image
        run: |
          cd backend
          docker build -t ${{ secrets.ECR_REPOSITORY }}/hs2-backend:${{ github.sha }} .
          docker push ${{ secrets.ECR_REPOSITORY }}/hs2-backend:${{ github.sha }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster hs2-${{ github.ref_name }} \
            --service hs2-backend \
            --force-new-deployment

      - name: Wait for deployment
        run: |
          aws ecs wait services-stable \
            --cluster hs2-${{ github.ref_name }} \
            --services hs2-backend

  smoke-test:
    needs: deploy
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Run smoke tests
        run: |
          pytest tests/integration/test_api_smoke.py \
            --base-url=https://hs2-${{ github.ref_name }}.yourdomain.com
```

---

## ğŸ“Š Monitoring & Observability

### CloudWatch Dashboards

Create custom dashboards for:

1. **Application Metrics**
   - Request rate (requests/min)
   - Error rate (4xx, 5xx)
   - Latency (P50, P95, P99)
   - TAEM evaluation duration

2. **Infrastructure Metrics**
   - ECS CPU/Memory utilization
   - RDS CPU/Memory/IOPS
   - Redis hit rate
   - ALB target health

3. **Business Metrics**
   - Assets evaluated per day
   - Average TAEM score
   - Rule failure rates
   - User activity (API calls per endpoint)

### CloudWatch Alarms

```hcl
# terraform/monitoring.tf

# High error rate alarm
resource "aws_cloudwatch_metric_alarm" "high_error_rate" {
  alarm_name          = "hs2-high-error-rate"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "5XXError"
  namespace           = "AWS/ApplicationELB"
  period              = "60"
  statistic           = "Sum"
  threshold           = "10"
  alarm_description   = "Triggers when 5xx errors exceed 10 in 2 minutes"
  alarm_actions       = [aws_sns_topic.alerts.arn]

  dimensions = {
    LoadBalancer = aws_lb.main.arn_suffix
  }
}

# High latency alarm
resource "aws_cloudwatch_metric_alarm" "high_latency" {
  alarm_name          = "hs2-high-latency"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "TargetResponseTime"
  namespace           = "AWS/ApplicationELB"
  period              = "60"
  statistic           = "Average"
  threshold           = "1.0"  # 1 second
  alarm_description   = "Triggers when avg response time > 1s for 2 minutes"
  alarm_actions       = [aws_sns_topic.alerts.arn]

  dimensions = {
    LoadBalancer = aws_lb.main.arn_suffix
  }
}

# RDS CPU alarm
resource "aws_cloudwatch_metric_alarm" "rds_cpu" {
  alarm_name          = "hs2-rds-high-cpu"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/RDS"
  period              = "300"
  statistic           = "Average"
  threshold           = "80"
  alarm_description   = "Triggers when RDS CPU > 80% for 10 minutes"
  alarm_actions       = [aws_sns_topic.alerts.arn]

  dimensions = {
    DBInstanceIdentifier = module.rds.db_instance_id
  }
}
```

### Logging Configuration

```python
# backend/app/core/logging_config.py
import logging
from pythonjsonlogger import jsonlogger

def setup_logging():
    """Configure structured JSON logging for CloudWatch"""

    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    logHandler = logging.StreamHandler()

    formatter = jsonlogger.JsonFormatter(
        '%(asctime)s %(name)s %(levelname)s %(message)s',
        rename_fields={
            'asctime': 'timestamp',
            'levelname': 'level',
            'name': 'logger'
        }
    )

    logHandler.setFormatter(formatter)
    logger.addHandler(logHandler)

    return logger
```

---

## ğŸ”’ Security Hardening

### Secrets Management

```bash
# Store secrets in AWS Secrets Manager
aws secretsmanager create-secret \
  --name hs2/prod/database-password \
  --secret-string "$(openssl rand -base64 32)"

# Reference in ECS task definition
{
  "secrets": [
    {
      "name": "DATABASE_PASSWORD",
      "valueFrom": "arn:aws:secretsmanager:us-east-1:123456789:secret:hs2/prod/database-password"
    }
  ]
}
```

### Network Security

```hcl
# Security group: ALB (public-facing)
resource "aws_security_group" "alb" {
  name        = "hs2-alb-sg"
  vpc_id      = module.vpc.vpc_id

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]  # Public HTTPS access
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# Security group: Backend (private)
resource "aws_security_group" "backend" {
  name        = "hs2-backend-sg"
  vpc_id      = module.vpc.vpc_id

  ingress {
    from_port       = 8000
    to_port         = 8000
    protocol        = "tcp"
    security_groups = [aws_security_group.alb.id]  # Only from ALB
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# Security group: RDS (database)
resource "aws_security_group" "rds" {
  name        = "hs2-rds-sg"
  vpc_id      = module.vpc.vpc_id

  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [aws_security_group.backend.id]  # Only from backend
  }
}
```

### WAF Rules

```hcl
resource "aws_wafv2_web_acl" "main" {
  name  = "hs2-waf"
  scope = "REGIONAL"

  default_action {
    allow {}
  }

  rule {
    name     = "RateLimitRule"
    priority = 1

    action {
      block {}
    }

    statement {
      rate_based_statement {
        limit              = 2000
        aggregate_key_type = "IP"
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "RateLimitRule"
      sampled_requests_enabled   = true
    }
  }

  rule {
    name     = "AWSManagedRulesCommonRuleSet"
    priority = 2

    override_action {
      none {}
    }

    statement {
      managed_rule_group_statement {
        name        = "AWSManagedRulesCommonRuleSet"
        vendor_name = "AWS"
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "AWSManagedRulesCommonRuleSet"
      sampled_requests_enabled   = true
    }
  }

  visibility_config {
    cloudwatch_metrics_enabled = true
    metric_name                = "hs2-waf"
    sampled_requests_enabled   = true
  }
}
```

---

## ğŸ“š Operations Runbook

### Common Tasks

#### Scaling Up/Down

```bash
# Scale ECS service
aws ecs update-service \
  --cluster hs2-prod \
  --service hs2-backend \
  --desired-count 6

# Scale RDS instance
aws rds modify-db-instance \
  --db-instance-identifier hs2-prod-db \
  --db-instance-class db.r5.2xlarge \
  --apply-immediately
```

#### Database Maintenance

```bash
# Manual RDS snapshot
aws rds create-db-snapshot \
  --db-instance-identifier hs2-prod-db \
  --db-snapshot-identifier hs2-manual-snapshot-$(date +%Y%m%d)

# Restore from snapshot
aws rds restore-db-instance-from-db-snapshot \
  --db-instance-identifier hs2-prod-db-restored \
  --db-snapshot-identifier hs2-manual-snapshot-20241125
```

#### Cache Flush

```bash
# Flush Redis cache
aws elasticache-redis-cli \
  --cluster-id hs2-prod-redis \
  --command "FLUSHALL"
```

#### Rollback Deployment

```bash
# List task definitions
aws ecs list-task-definitions --family-prefix hs2-backend

# Rollback to previous version
aws ecs update-service \
  --cluster hs2-prod \
  --service hs2-backend \
  --task-definition hs2-backend:42  # Previous version
```

---

## ğŸ†˜ Troubleshooting

### Issue: High Latency

**Symptoms**: API response times > 1 second

**Investigation**:
```bash
# Check CloudWatch Logs
aws logs tail /ecs/hs2-backend --follow

# Check RDS performance
aws rds describe-db-instances \
  --db-instance-identifier hs2-prod-db \
  --query 'DBInstances[0].{CPU:CPUUtilization,IOPS:ReadIOPS}'

# Check slow queries
docker compose exec postgres psql -U gpr_user -d gpr_db
SELECT * FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 10;
```

**Resolution**:
1. Scale up ECS tasks if CPU/memory high
2. Add database indexes for slow queries
3. Refresh materialized views if stale
4. Check Redis cache hit rate

### Issue: Database Connection Errors

**Symptoms**: "Too many connections" or "Connection refused"

**Investigation**:
```bash
# Check active connections
SELECT count(*), state FROM pg_stat_activity GROUP BY state;

# Check connection limits
SHOW max_connections;
```

**Resolution**:
1. Increase RDS max_connections parameter
2. Implement connection pooling (PgBouncer)
3. Check for connection leaks in application code

### Issue: Failed Deployment

**Symptoms**: ECS tasks failing health checks

**Investigation**:
```bash
# Check task logs
aws ecs describe-tasks \
  --cluster hs2-prod \
  --tasks <task-id>

# View CloudWatch Logs
aws logs get-log-events \
  --log-group-name /ecs/hs2-backend \
  --log-stream-name ecs/backend/<task-id>
```

**Resolution**:
1. Check environment variables in task definition
2. Verify database connectivity from private subnet
3. Check for application errors in logs
4. Rollback to previous version if critical

---

## ğŸ“ Support

### On-Call Escalation

1. **Severity 1** (Production down): Page on-call engineer via PagerDuty
2. **Severity 2** (Degraded performance): Slack #hs2-alerts channel
3. **Severity 3** (Non-urgent): Create JIRA ticket

### Contact Information

- **Platform Team**: platform-team@yourdomain.com
- **On-Call**: pagerduty.com/services/hs2-platform
- **Slack**: #hs2-platform-support
- **Documentation**: https://docs.yourdomain.com/hs2

---

**Deployment Guide Version**: 1.0
**Last Updated**: November 25, 2024

**Related Documents**:
- [HS2_ORCHESTRATION_PLAN.md](../HS2_ORCHESTRATION_PLAN.md)
- [DEMO_SCRIPT.md](./DEMO_SCRIPT.md)
- [DATA_DICTIONARY.md](./DATA_DICTIONARY.md)
